import numpy as np
import matplotlib.pyplot as plt
import os
from utils.image_io import read_image, save_compressed_file
from utils.metrics import calculate_psnr
from core.color_processing.color_transform import rgb_to_ycbcr, ycbcr_to_rgb
from core.color_processing.subsampling import apply_chroma_subsampling
from core.dct.block_processing import pad_image_to_multiple_of_8, split_into_blocks, merge_blocks
from core.dct.dct import apply_dct_to_image, apply_idct_to_image
from core.quantization.quantization import optimize_quantization_for_speed
from core.quantization.dequantization import optimize_dequantization_for_speed
from core.entropy_coding.zigzag_rle import apply_zigzag_and_rle, apply_inverse_zigzag_and_rle
from core.entropy_coding.huffman.huffman_encoder import build_frequency_table, build_huffman_tree, build_huffman_codes, huffman_encode
from core.entropy_coding.huffman.huffman_decoder import huffman_decode_bitstring

class JPEGProcessor:
    """
    L·ªõp x·ª≠ l√Ω pipeline n√©n v√† gi·∫£i n√©n JPEG, h·ªó tr·ª£ visualization cho Streamlit.
    
    Attributes:
    -----------
    quality : int
        H·ªá s·ªë ch·∫•t l∆∞·ª£ng (1-100)
    intermediates : dict
        L∆∞u k·∫øt qu·∫£ trung gian c·ªßa c√°c b∆∞·ªõc
    """
    def __init__(self, quality=50):
        if not 1 <= quality <= 100:
            raise ValueError("H·ªá s·ªë ch·∫•t l∆∞·ª£ng ph·∫£i t·ª´ 1 ƒë·∫øn 100")
        self.quality = quality
        self.intermediates = {}

    def encode_pipeline(self, image):
        """
        Pipeline n√©n JPEG, l∆∞u k·∫øt qu·∫£ trung gian.
        
        Parameters:
        -----------
        image : ndarray
            ·∫¢nh ƒë·∫ßu v√†o: (h, w) ho·∫∑c (h, w, 3), dtype=float32, gi√° tr·ªã [0, 255]
        
        Returns:
        --------
        dict
            {
                'encoded_data': bytes,
                'dc_codes': dict,
                'ac_codes': dict,
                'shape': tuple,
                'total_bits': int,
                'intermediates': dict
            }
        """
        self.intermediates = {}
        
        # Ki·ªÉm tra ƒë·∫ßu v√†o
        if image.ndim not in (2, 3):
            raise ValueError("·∫¢nh ph·∫£i l√† m·∫£ng 2D (x√°m) ho·∫∑c 3D (m√†u)")
        if image.max() > 255 or image.min() < 0:
            raise ValueError("Gi√° tr·ªã pixel ph·∫£i n·∫±m trong [0, 255]")
        self.intermediates['input'] = image.copy()
        
        # B∆∞·ªõc 1: Chuy·ªÉn RGB sang YCbCr n·∫øu l√† ·∫£nh m√†u
        if image.ndim == 3:
            image = rgb_to_ycbcr(image)
            self.intermediates['ycbcr'] = image.copy()
        
        # B∆∞·ªõc 2: Padding ·∫£nh v√† chia th√†nh c√°c kh·ªëi 8x8
        image = pad_image_to_multiple_of_8(image)
        blocks = split_into_blocks(image)
        print("Blocks shape:", blocks.shape)
        if blocks.ndim == 4:
            num_blocks = blocks.shape[0] * blocks.shape[1]  # ·∫£nh x√°m
        else:
            num_blocks = blocks.shape[1] * blocks.shape[2]  # ·∫£nh m√†u

        print(f"T·ªïng s·ªë block: {num_blocks}")
        self.intermediates['blocks'] = blocks.copy()
        
        # B∆∞·ªõc 3: DCT
        dct_blocks = apply_dct_to_image(blocks)
        print("DCT shape:", dct_blocks.shape)
        self.intermediates['dct'] = dct_blocks.copy()
        
        # B∆∞·ªõc 4: L∆∞·ª£ng t·ª≠ h√≥a
        print("Quality at quantization:", self.quality)
        quant_blocks = optimize_quantization_for_speed(dct_blocks, self.quality)
        print("Quantized shape:", quant_blocks.shape)
        self.intermediates['quantized'] = quant_blocks.copy()
        
        # B∆∞·ªõc 5: Zigzag v√† RLE
        rle_data = apply_zigzag_and_rle(quant_blocks)
        print("S·ªë block sau Zigzag + RLE:", len(rle_data))
        self.intermediates['rle'] = rle_data
        print("\nüîç Sample rle_data (first 3 blocks):")
        for i, block in enumerate(rle_data[:3]):
            print(f"Block {i}: {block}")
        
        # B∆∞·ªõc 6: Huffman
        dc_freq, ac_freq = build_frequency_table(rle_data)
        dc_tree = build_huffman_tree(dc_freq)
        ac_tree = build_huffman_tree(ac_freq)
        dc_codes = build_huffman_codes(dc_tree)
        ac_codes = build_huffman_codes(ac_tree)
        encoded_data, total_bits = huffman_encode(rle_data, dc_codes, ac_codes)
        # L∆∞u shape
        if blocks.ndim == 4:
            # ·∫¢nh x√°m
            padded_shape = (blocks.shape[0] * 8, blocks.shape[1] * 8)
        elif blocks.ndim == 5:
            # ·∫¢nh m√†u
            padded_shape = (blocks.shape[0], blocks.shape[1] * 8, blocks.shape[2] * 8)
        
        return {
            'encoded_data': encoded_data,
            'dc_codes': dc_codes,
            'ac_codes': ac_codes,
            'padded_shape': padded_shape,
            'total_bits': total_bits,
            'intermediates': self.intermediates
        }

    def decode_pipeline(self, encoded_data, dc_codes, ac_codes, padded_shape, total_bits, original_shape):
        """
        Pipeline gi·∫£i n√©n JPEG, l∆∞u k·∫øt qu·∫£ trung gian.
        
        Parameters:
        -----------
        encoded_data : bytes
            D·ªØ li·ªáu m√£ h√≥a
        dc_codes : dict
            B·∫£ng m√£ Huffman cho DC
        ac_codes : dict
            B·∫£ng m√£ Huffman cho AC
        shape : tuple
            Shape g·ªëc: (h, w) ho·∫∑c (c, h, w)
        
        Returns:
        --------
        dict
            {
                'image': ndarray,
                'intermediates': dict
            }
        """
        self.intermediates = {}
        
        # Ki·ªÉm tra ƒë·∫ßu v√†o
        if not encoded_data or not dc_codes or not ac_codes:
            raise ValueError("D·ªØ li·ªáu v√† b·∫£ng m√£ ph·∫£i kh√¥ng r·ªóng")
        if len(padded_shape) not in (2, 3):
            raise ValueError("shape ph·∫£i l√† (h, w) ho·∫∑c (c, h, w)")
        
        # B∆∞·ªõc 1: Gi·∫£i m√£ Huffman
        rle_data = huffman_decode_bitstring(encoded_data, dc_codes, ac_codes, total_bits)
        print("rle_data type:", type(rle_data))
        print("rle_data length:", len(rle_data))
        print("First element type:", type(rle_data[0]))
        self.intermediates['rle'] = rle_data
        
        # B∆∞·ªõc 2: Gi·∫£i RLE v√† zigzag
        quant_blocks = apply_inverse_zigzag_and_rle(rle_data, padded_shape)
        self.intermediates['quantized'] = quant_blocks.copy()
        
        # B∆∞·ªõc 3: Gi·∫£i l∆∞·ª£ng t·ª≠ h√≥a
        print("Quality at dequantization:", self.quality)
        dct_blocks = optimize_dequantization_for_speed(quant_blocks, self.quality)
        self.intermediates['dct'] = dct_blocks.copy()
        
        # B∆∞·ªõc 4: IDCT
        pixel_blocks = apply_idct_to_image(dct_blocks)
        self.intermediates['blocks'] = pixel_blocks.copy()
        
        # B∆∞·ªõc 5: G·ªôp kh·ªëi
        image = merge_blocks(pixel_blocks, original_shape)
        self.intermediates['merged'] = image.copy()
        
        # B∆∞·ªõc 6: Chuy·ªÉn YCbCr sang RGB n·∫øu l√† ·∫£nh m√†u
        if image.ndim == 3:
            image = ycbcr_to_rgb(image)
            self.intermediates['rgb'] = image.copy()
        print("Image shape:", image.shape)
        return image.astype(np.uint8)
        # return {
        #     'image': image,
        #     'intermediates': self.intermediates
        # }

    def save_intermediate_images(self, output_dir):
        """
        L∆∞u k·∫øt qu·∫£ trung gian d∆∞·ªõi d·∫°ng ·∫£nh ƒë·ªÉ Streamlit visualize.
        
        Parameters:
        -----------
        output_dir : str
            Th∆∞ m·ª•c l∆∞u ·∫£nh
        """
        if not os.path.exists(output_dir):
            os.makedirs(output_dir)
        
        for step, data in self.intermediates.items():
            if step in ('input', 'ycbcr', 'merged', 'rgb'):
                plt.imsave(f"{output_dir}/{step}.png", data.astype(np.uint8), cmap='gray' if data.ndim == 2 else None)
            elif step == 'blocks':
                if data.ndim == 4:
                    img = merge_blocks(data)
                    plt.imsave(f"{output_dir}/{step}.png", img.astype(np.uint8), cmap='gray')
                else:
                    for ch in range(data.shape[0]):
                        img = merge_blocks(data[ch])
                        plt.imsave(f"{output_dir}/{step}_ch{ch}.png", img.astype(np.uint8), cmap='gray')
            elif step in ('dct', 'quantized'):
                if data.ndim == 4:
                    sample = data[0, 0]
                    plt.figure()
                    plt.imshow(sample, cmap='hot')
                    plt.colorbar()
                    plt.savefig(f"{output_dir}/{step}_sample.png")
                    plt.close()
                else:
                    for ch in range(data.shape[0]):
                        sample = data[ch, 0, 0]
                        plt.figure()
                        plt.imshow(sample, cmap='hot')
                        plt.colorbar()
                        plt.savefig(f"{output_dir}/{step}_ch{ch}_sample.png")
                        plt.close()

    def compare_images(self, img1, img2):
        """
        So s√°nh hai ·∫£nh b·∫±ng PSNR.
        
        Parameters:
        -----------
        img1, img2 : ndarray
            Hai ·∫£nh c√πng shape, dtype=float32, gi√° tr·ªã [0, 255]
        
        Returns:
        --------
        float
            Gi√° tr·ªã PSNR (dB)
        """
        return calculate_psnr(img1, img2)